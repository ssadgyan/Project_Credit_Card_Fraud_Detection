{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "qOLRZ5jgop5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rHoi-qoZnshZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# For imbalance handling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Model saving\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fxi8X6dFyNA",
        "outputId": "e80e5ac4-047e-4177-e6be-7483b4a61b20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/creditcard.csv\")\n"
      ],
      "metadata": {
        "id": "AKwQR_pboQbs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "06ABKFxIN9gi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape:\", data.shape)\n",
        "print(\"Class distribution:\\n\", data['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHrDwmEROAZq",
        "outputId": "bf7f7c5a-27bb-4ce9-e90f-74c3f309c0a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (284807, 31)\n",
            "Class distribution:\n",
            " Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPROCESSING**"
      ],
      "metadata": {
        "id": "7aavXjSaOGUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Amount\n",
        "scaler = StandardScaler()\n",
        "data['Amount'] = scaler.fit_transform(data[['Amount']])\n",
        "\n",
        "# Drop Time\n",
        "data = data.drop(['Time'], axis=1)\n",
        "\n",
        "# Drop duplicates if any\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "print(\"Final Shape:\", data.shape)\n",
        "print(\"Class distribution after cleaning:\\n\", data['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gefr3iXODPk",
        "outputId": "0320ec5c-63b3-4749-c207-8545df0bee58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Shape: (275663, 30)\n",
            "Class distribution after cleaning:\n",
            " Class\n",
            "0    275190\n",
            "1       473\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/Test Split**"
      ],
      "metadata": {
        "id": "FotxcE5POT90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Stratify ensures fraud cases distributed properly\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "lxQyiU9uOQFS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handle Imbalance with SMOTE**"
      ],
      "metadata": {
        "id": "EiWYjdRbOdCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"After SMOTE:\\n\", y_train_res.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvVB376SOZi4",
        "outputId": "1f4a8e5d-c1e7-4d04-8284-11764163b043"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After SMOTE:\n",
            " Class\n",
            "0    220152\n",
            "1    220152\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Pipeline Model**"
      ],
      "metadata": {
        "id": "ChxebUxROg_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline ensures scaling + classifier integrated\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),   # standardize features\n",
        "    ('rf', RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit model\n",
        "pipeline.fit(X_train_res, y_train_res)\n",
        "\n",
        "joblib.dump(pipeline, \"credit_card_model.pkl\")\n",
        "print(\"✅ Model saved as credit_card_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAi1Q_1COpkf",
        "outputId": "2c53e8d0-8317-407c-a497-89515b826dc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved as credit_card_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate**"
      ],
      "metadata": {
        "id": "wyK7nSiLWztR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Probability scoring (important for fraud detection)\n",
        "y_proba = pipeline.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ7sr_ihOshc",
        "outputId": "c4d4ae9f-545b-4148-df15-7ebbf7fc4679"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     55038\n",
            "           1       0.83      0.78      0.80        95\n",
            "\n",
            "    accuracy                           1.00     55133\n",
            "   macro avg       0.92      0.89      0.90     55133\n",
            "weighted avg       1.00      1.00      1.00     55133\n",
            "\n",
            "Confusion Matrix:\n",
            " [[55023    15]\n",
            " [   21    74]]\n",
            "ROC-AUC Score: 0.9626563273986775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we doing a Test With a Fraud Sample**"
      ],
      "metadata": {
        "id": "fdatC_R5W7nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take first fraud transaction row\n",
        "fraud_sample = data[data['Class']==1].iloc[0].drop('Class')\n",
        "fraud_array = fraud_sample.values.reshape(1, -1)\n",
        "\n",
        "print(\"Fraud sample prediction:\", pipeline.predict(fraud_array))\n",
        "print(\"Fraud sample prob:\", pipeline.predict_proba(fraud_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3CTC7VLW6L7",
        "outputId": "59e49be2-c2a3-49a8-fa9a-a2a14ddd2cdf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud sample prediction: [1]\n",
            "Fraud sample prob: [[0.01 0.99]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we checking Normal Transaction**"
      ],
      "metadata": {
        "id": "ReXgNvVkXNjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take first normal transaction row\n",
        "normal_sample = data[data['Class']==0].iloc[0].drop('Class')\n",
        "normal_array = normal_sample.values.reshape(1, -1)\n",
        "\n",
        "print(\"Normal sample prediction:\", pipeline.predict(normal_array))\n",
        "print(\"Normal sample prob:\", pipeline.predict_proba(normal_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVYBtV0XYBPH",
        "outputId": "0c6ace85-4c6f-44a8-eab6-e966a8c0ec86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal sample prediction: [0]\n",
            "Normal sample prob: [[1. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}